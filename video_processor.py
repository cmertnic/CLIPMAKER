import time
import cv2
import numpy as np
import sys
from moviepy.editor import VideoFileClip
from pydub import AudioSegment
import subprocess
import os

from config import CFG
from utils import log
from models import ProcessingState, FrameSettings
from frame_processor import crop_to_vertical_with_frame, crop_to_vertical
from subtitle_engine import add_subtitles_to_clip_advanced

def safe_progress_bar(iterable, desc="", log_callback=None, progress_callback=None, total=None):
    """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –¥–ª—è exe –∏ –æ–±—ã—á–Ω–æ–≥–æ Python"""
    items = list(iterable)
    if total is None:
        total = len(items)
    
    for i, item in enumerate(items):
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 100 –∏—Ç–µ—Ä–∞—Ü–∏–π –∏–ª–∏ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π
        if i % 100 == 0 or i == len(items) - 1:
            progress_percent = (i / len(items)) * 100
            status = f"{desc}: {progress_percent:.1f}%"
            
            if log_callback:
                log_callback(status)
            
            if progress_callback:
                # –ü–µ—Ä–µ–¥–∞–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å (0-100) –∏ —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—É—Å–∞
                progress_callback(progress_percent * 0.5, status)
        
        yield item

def analyze_video_advanced(video_path: str, analysis_duration: int, log_func, state: ProcessingState, progress_callback) -> list:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∞–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–∞–º—ã—Ö –≤–∏—Ä—É—Å–Ω—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤"""
    start_time = time.time()
    log_func("üîç –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ –Ω–∞ –≤–∏—Ä—É—Å–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã...", "INFO")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–∏–¥–µ–æ
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ")
        
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = total_frames / fps
    
    log_func(f"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤–∏–¥–µ–æ: FPS={fps}, Frames={total_frames}, Duration={duration:.1f}—Å", "INFO")
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∞–Ω–∞–ª–∏–∑
    analysis_frames = min(int(analysis_duration * fps), total_frames)
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—É–¥–∏–æ –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    audio_path = CFG["TEMP_DIR"] / "temp_audio.wav"
    try:
        subprocess.run([
            'ffmpeg', '-i', video_path, '-vn', '-acodec', 'pcm_s16le', 
            '-ar', '44100', '-ac', '2', str(audio_path), '-y'
        ], check=True, capture_output=True)
    except subprocess.CalledProcessError:
        log_func("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∞—É–¥–∏–æ", "WARNING")
        return []

    # –ê–Ω–∞–ª–∏–∑ –∞—É–¥–∏–æ - –∏—â–µ–º –º–æ–º–µ–Ω—Ç—ã —Å –≤—ã—Å–æ–∫–æ–π —ç–Ω–µ—Ä–≥–∏–µ–π
    audio = AudioSegment.from_file(str(audio_path))
    audio_samples = np.array(audio.get_array_of_samples())
    if audio.channels == 2:
        audio_samples = audio_samples.reshape((-1, 2)).mean(axis=1)
    
    # –ê–Ω–∞–ª–∏–∑ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º (0.5 —Å–µ–∫—É–Ω–¥—ã)
    segment_length = int(audio.frame_rate * 0.5)
    audio_energy = []
    
    for i in range(0, len(audio_samples) - segment_length, segment_length):
        segment = audio_samples[i:i+segment_length]
        energy = np.sqrt(np.mean(segment**2))
        time_sec = i / audio.frame_rate
        audio_energy.append((time_sec, energy))
    
    # –ù–∞—Ö–æ–¥–∏–º –ø–∏–∫–∏ —ç–Ω–µ—Ä–≥–∏–∏ (—Ç–æ–ø 10%)
    energy_values = [e[1] for e in audio_energy]
    energy_threshold = np.percentile(energy_values, 90)
    audio_peaks = [e[0] for e in audio_energy if e[1] > energy_threshold]
    
    log_func(f"üîä –ù–∞–π–¥–µ–Ω–æ {len(audio_peaks)} –∞—É–¥–∏–æ-–ø–∏–∫–æ–≤", "INFO")
    
    # –ê–Ω–∞–ª–∏–∑ –¥–≤–∏–∂–µ–Ω–∏—è —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º
    motion_scores = []
    optical_flow_scores = []
    
    ret, prev_frame = cap.read()
    if not ret:
        return []
        
    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)
    prev_gray = cv2.GaussianBlur(prev_gray, (21, 21), 0)
    
    # –î–µ—Ç–µ–∫—Ç–æ—Ä –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–µ–π –¥–ª—è –æ–ø—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ—Ç–æ–∫–∞
    feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)
    p0 = cv2.goodFeaturesToTrack(prev_gray, mask=None, **feature_params)
    
    # –ó–ê–ú–ï–ù–ê: –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –≤–º–µ—Å—Ç–æ tqdm
    frame_range = range(1, analysis_frames, max(1, int(fps/2)))
    for frame_num in safe_progress_bar(
        frame_range, 
        desc="–ê–Ω–∞–ª–∏–∑ –¥–≤–∏–∂–µ–Ω–∏—è",
        log_callback=log_func,
        progress_callback=progress_callback,
        total=len(frame_range)
    ):
        ret, frame = cap.read()
        if not ret:
            break
            
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        gray = cv2.GaussianBlur(gray, (21, 21), 0)
        
        # –î–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–≤–∏–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ —Ä–∞–∑–Ω–∏—Ü—É –∫–∞–¥—Ä–æ–≤
        frame_delta = cv2.absdiff(prev_gray, gray)
        thresh = cv2.threshold(frame_delta, 25, 255, cv2.THRESH_BINARY)[1]
        thresh = cv2.dilate(thresh, None, iterations=2)
        contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        motion_area = sum(cv2.contourArea(c) for c in contours)
        motion_scores.append((frame_num / fps, motion_area))
        
        # –û–ø—Ç–∏—á–µ—Å–∫–∏–π –ø–æ—Ç–æ–∫ –¥–ª—è –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–ª–æ–∂–Ω–æ–≥–æ –¥–≤–∏–∂–µ–Ω–∏—è
        if p0 is not None:
            p1, st, err = cv2.calcOpticalFlowPyrLK(prev_gray, gray, p0, None)
            if p1 is not None:
                good_new = p1[st == 1]
                good_old = p0[st == 1]
                if len(good_new) > 0:
                    flow_magnitude = np.mean(np.sqrt(np.sum((good_new - good_old)**2, axis=1)))
                    optical_flow_scores.append((frame_num / fps, flow_magnitude))
        
        prev_gray = gray
        if p0 is not None:
            p0 = cv2.goodFeaturesToTrack(prev_gray, mask=None, **feature_params)
        
        if state.is_stopped:
            break
            
        # –ü—Ä–æ–≥—Ä–µ—Å—Å —Ç–µ–ø–µ—Ä—å –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –≤ safe_progress_bar
    
    cap.release()
    
    # –ù–∞—Ö–æ–¥–∏–º –ø–∏–∫–∏ –¥–≤–∏–∂–µ–Ω–∏—è
    motion_values = [m[1] for m in motion_scores]
    motion_threshold = np.percentile(motion_values, 85)
    motion_peaks = [m[0] for m in motion_scores if m[1] > motion_threshold]
    
    # –ù–∞—Ö–æ–¥–∏–º –ø–∏–∫–∏ –æ–ø—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ—Ç–æ–∫–∞
    if optical_flow_scores:
        flow_values = [f[1] for f in optical_flow_scores]
        flow_threshold = np.percentile(flow_values, 85)
        flow_peaks = [f[0] for f in optical_flow_scores if f[1] > flow_threshold]
    else:
        flow_peaks = []
    
    log_func(f"üé• –ù–∞–π–¥–µ–Ω–æ {len(motion_peaks)} –ø–∏–∫–æ–≤ –¥–≤–∏–∂–µ–Ω–∏—è, {len(flow_peaks)} –ø–∏–∫–æ–≤ –æ–ø—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ—Ç–æ–∫–∞", "INFO")
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –ø–∏–∫–∏
    all_peaks = set(audio_peaks + motion_peaks + flow_peaks)
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –±–ª–∏–∑–∫–∏–µ –ø–∏–∫–∏ –∏ –æ—Ü–µ–Ω–∏–≤–∞–µ–º –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å
    peak_groups = []
    sorted_peaks = sorted(all_peaks)
    
    current_group = []
    for peak in sorted_peaks:
        if not current_group or peak - current_group[-1] <= 5.0:
            current_group.append(peak)
        else:
            if len(current_group) >= 2:
                peak_groups.append(current_group)
            current_group = [peak]
    
    if len(current_group) >= 2:
        peak_groups.append(current_group)
    
    # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–µ –º–æ–º–µ–Ω—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ –ø–∏–∫–æ–≤
    best_moments = []
    for group in peak_groups:
        if len(group) >= 3:
            center = np.mean(group)
            intensity = len(group)
            best_moments.append((center, intensity))
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç–∏
    best_moments.sort(key=lambda x: x[1], reverse=True)
    
    # –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞ –æ–ø—Ü–∏—è "–≤—Å–µ –∫–ª–∏–ø—ã", –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Å–µ –º–æ–º–µ–Ω—Ç—ã
    if state.create_all_clips:
        selected_moments = [moment[0] for moment in best_moments]
        log_func(f"üéØ –†–µ–∂–∏–º '–í—Å–µ –∫–ª–∏–ø—ã': –Ω–∞–π–¥–µ–Ω–æ {len(selected_moments)} –º–æ–º–µ–Ω—Ç–æ–≤", "INFO")
    else:
        selected_moments = [moment[0] for moment in best_moments[:min(state.clip_count, len(best_moments))]]
        log_func(f"üéØ –ù–∞–π–¥–µ–Ω–æ {len(selected_moments)} –≤–∏—Ä—É—Å–Ω—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤", "INFO")
    
    analysis_time = time.time() - start_time
    log_func(f"‚è±Ô∏è –í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {analysis_time:.1f}—Å", "INFO")
    
    return selected_moments

def create_clips_from_best_moments(video_path: str, moments: list, clip_count: int, clip_duration: float, 
                                 min_clip_duration: float, max_clip_duration: float, crop_to_shorts: bool, 
                                 create_all_clips: bool, add_frame: bool, frame_settings: FrameSettings,
                                 log_func, state: ProcessingState, progress_callback) -> list:
    """–°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∏–ø–æ–≤ –∏–∑ –ª—É—á—à–∏—Ö –º–æ–º–µ–Ω—Ç–æ–≤"""
    start_time = time.time()
    
    if create_all_clips:
        log_func(f"üé¨ –°–æ–∑–¥–∞–Ω–∏–µ –≤—Å–µ—Ö {len(moments)} –≤–∏—Ä—É—Å–Ω—ã—Ö –∫–ª–∏–ø–æ–≤", "INFO")
        actual_clip_count = len(moments)
    else:
        log_func(f"üé¨ –°–æ–∑–¥–∞–Ω–∏–µ {clip_count} –∫–ª–∏–ø–æ–≤ –∏–∑ {len(moments)} –ª—É—á—à–∏—Ö –º–æ–º–µ–Ω—Ç–æ–≤", "INFO")
        actual_clip_count = min(clip_count, len(moments))
    
    try:
        video = VideoFileClip(video_path)
        total_duration = video.duration
        
        clips_created = []
        used_moments = set()
        
        for i in range(actual_clip_count):
            if state.is_stopped:
                break
                
            moment = moments[i]
            
            if moment in used_moments:
                continue
                
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã –∫–ª–∏–ø–∞
            start_time_clip = max(0, moment - clip_duration / 2)
            end_time_clip = min(total_duration, moment + clip_duration / 2)
            
            # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –¥–ª—è Shorts
            target_duration = 59.0
            if crop_to_shorts:
                if end_time_clip - start_time_clip > target_duration:
                    start_time_clip = max(0, moment - target_duration / 2)
                    end_time_clip = min(total_duration, start_time_clip + target_duration)
            
            # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–ø
            try:
                clip = video.subclip(start_time_clip, end_time_clip)
                
                # –û–±—Ä–µ–∑–∞–µ–º –ø–æ–¥ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞ –æ–ø—Ü–∏—è Shorts
                if crop_to_shorts:
                    if add_frame:
                        clip = crop_to_vertical_with_frame(clip, frame_settings)
                        frame_style = frame_settings.frame_style
                        log_func(f"üì± –û–±—Ä–µ–∑–∫–∞ –ø–æ–¥ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Å {frame_style} —Ä–∞–º–∫–∞–º–∏", "DEBUG")
                    else:
                        clip = crop_to_vertical(clip)
                        log_func(f"üì± –û–±—Ä–µ–∑–∫–∞ –ø–æ–¥ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç (9:16)", "DEBUG")
                
                from config import OUT
                if create_all_clips:
                    output_path = OUT / f"viral_clip_{i+1:02d}_{int(start_time_clip)}s-{int(end_time_clip)}s.mp4"
                else:
                    output_path = OUT / f"shorts_clip_{i+1:02d}_{int(start_time_clip)}s-{int(end_time_clip)}s.mp4"
                
                clip.write_videofile(
                    str(output_path), 
                    codec="libx264", 
                    audio_codec="aac", 
                    verbose=False, 
                    logger=None,
                    threads=4,
                    temp_audiofile=str(CFG["TEMP_DIR"] / f"temp_audio_{i}.m4a")
                )
                clip.close()
                
                clips_created.append(str(output_path))
                used_moments.add(moment)
                
                if create_all_clips:
                    log_func(f"‚úÖ –í–∏—Ä—É—Å–Ω—ã–π –∫–ª–∏–ø {i+1}: {output_path.name} (—Ü–µ–Ω—Ç—Ä: {moment:.1f}—Å)", "INFO")
                else:
                    log_func(f"‚úÖ Shorts –∫–ª–∏–ø {i+1}: {output_path.name} (—Ü–µ–Ω—Ç—Ä: {moment:.1f}—Å)", "INFO")
                
            except Exception as e:
                log_func(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∫–ª–∏–ø–∞ {i+1}: {e}", "WARNING")
                continue
            
            progress = (i + 1) / actual_clip_count * 100
            progress_callback(33.33 + progress * 0.33, f"–°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∏–ø–∞ {i+1}/{actual_clip_count}")
        
        video.close()
        
        process_time = time.time() - start_time
        if create_all_clips:
            log_func(f"üé¨ –°–æ–∑–¥–∞–Ω–æ {len(clips_created)} –≤–∏—Ä—É—Å–Ω—ã—Ö –∫–ª–∏–ø–æ–≤ –∑–∞ {process_time:.1f}—Å", "INFO")
        else:
            log_func(f"üé¨ –°–æ–∑–¥–∞–Ω–æ {len(clips_created)} Shorts –∫–ª–∏–ø–æ–≤ –∑–∞ {process_time:.1f}—Å", "INFO")
        return clips_created
        
    except Exception as e:
        log_func(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∫–ª–∏–ø–æ–≤: {e}", "ERROR")
        return []

def process_video_thread(state: ProcessingState, progress_callback, log_callback):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ"""
    try:
        state.is_processing = True
        state.start_time = time.time()
        state.progress = 0.0
        state.current_stage = "–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ"
        
        log_callback("üöÄ –ù–∞—á–∏–Ω–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –≤–∏–¥–µ–æ...", "INFO")
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        from config import OUT, CFG
        OUT.mkdir(exist_ok=True)
        CFG["TEMP_DIR"].mkdir(exist_ok=True)
        
        # –®–∞–≥ 1: –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ
        progress_callback(0, "–ü–æ–∏—Å–∫ –≤–∏—Ä—É—Å–Ω—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤...")
        moments = analyze_video_advanced(state.video_path, state.analysis_duration, log_callback, state, progress_callback)
        
        if state.is_stopped or not moments:
            log_callback("üõë –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∏–ª–∏ –º–æ–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã", "INFO")
            return
        
        # –®–∞–≥ 2: –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∏–ø–æ–≤
        state.current_stage = "–°–æ–∑–¥–∞–Ω–∏–µ –≤–∏—Ä—É—Å–Ω—ã—Ö –∫–ª–∏–ø–æ–≤"
        progress_callback(33.33, "–°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∏–ø–æ–≤...")
        clips = create_clips_from_best_moments(
            state.video_path, moments, state.clip_count, state.clip_duration, 
            state.min_clip_duration, state.max_clip_duration, state.crop_to_shorts,
            state.create_all_clips, state.add_frame, state.frame_settings,
            log_callback, state, progress_callback
        )
        
        if state.is_stopped or not clips:
            log_callback("üõë –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∏–ª–∏ –∫–ª–∏–ø—ã –Ω–µ —Å–æ–∑–¥–∞–Ω—ã", "INFO")
            return
        
        # –®–∞–≥ 3: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å—É–±—Ç–∏—Ç—Ä–æ–≤
        if state.use_subtitles:
            state.current_stage = "–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å—É–±—Ç–∏—Ç—Ä–æ–≤"
            progress_callback(66.66, "–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å—É–±—Ç–∏—Ç—Ä–æ–≤...")
            
            successful_clips = []
            for i, clip_path in enumerate(clips):
                if state.is_stopped:
                    break
                    
                try:
                    new_clip_path = add_subtitles_to_clip_advanced(clip_path, state.subtitle_settings, log_callback)
                    if new_clip_path != clip_path:
                        import os
                        if os.path.exists(clip_path):
                            os.remove(clip_path)
                        successful_clips.append(new_clip_path)
                    else:
                        successful_clips.append(clip_path)
                        
                except Exception as e:
                    log_callback(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–ª–∏–ø–∞ {i+1}: {e}", "WARNING")
                    successful_clips.append(clip_path)
                
                progress = (i + 1) / len(clips) * 100
                progress_callback(66.66 + progress * 0.33, f"–°—É–±—Ç–∏—Ç—Ä—ã –∫ –∫–ª–∏–ø—É {i+1}/{len(clips)}")
            
            clips = successful_clips
        
        # –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ
        state.clips_created = clips
        state.progress = 100.0
        state.current_stage = "–ì–æ—Ç–æ–≤–æ"
        
        total_time = time.time() - state.start_time
        if state.create_all_clips:
            log_callback(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –°–æ–∑–¥–∞–Ω–æ {len(clips)} –≤–∏—Ä—É—Å–Ω—ã—Ö –∫–ª–∏–ø–æ–≤ –∑–∞ {total_time:.1f}—Å", "INFO")
        else:
            log_callback(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –°–æ–∑–¥–∞–Ω–æ {len(clips)} Shorts –∫–ª–∏–ø–æ–≤ –∑–∞ {total_time:.1f}—Å", "INFO")
        
    except Exception as e:
        import traceback
        log_callback(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}", "ERROR")
        log_callback(traceback.format_exc(), "DEBUG")
    finally:
        state.is_processing = False
        state.is_paused = False